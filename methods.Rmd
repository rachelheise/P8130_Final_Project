---
title: "Methods"
output:
  html_document:
    df_print: paged
---

```{r setup, echo = FALSE, message = FALSE, warning = FALSE}
library(tinytex)
library(tidyverse)
library(arsenal)

theme_set(theme_minimal())
```

# Data Cleaning

Read and clean hate crime data.

```{r message = FALSE, warning = FALSE}
hate_df =
  read_csv("./data/HateCrimes.csv") %>% 
  mutate(
    state = as.factor(state),
    unemployment = as.factor(unemployment),
    urbanization = as.factor(urbanization),
    hate_crimes_per_100k_splc = as.numeric(hate_crimes_per_100k_splc)
  )
```

# Descriptive Statistics

Create table of descriptive statistics.

```{r}
# Table labels
my_labels =
  list(
    unemployment = "Unemployment",
    urbanization = "Urbanization",
    median_household_income = "Median Household Income",
    perc_population_with_high_school_degree = "Percent with HS Degree",
    perc_non_citizen = "Percent Non-Citizen",
    gini_index = "Gini Index",
    perc_non_white = "Percent Non-White",
    hate_crimes_per_100k_splc = "Hate Crimes per 100k"
)

# Table controls
my_controls = tableby.control(
  total = F,
  test = F,
  numeric.stats = c("N", "meansd", "medianq1q3", "range", "Nmiss2"),
  cat.stats = c("N", "countpct"),
  stats.labels = list(
    meansd = "Mean (SD)",
    medianq1q3 = "Median (Q1, Q3)",
    range = "Min - Max",
    Nmiss2 = "Missing",
    countpct = "N (%)",
    N = "N"
    )
  )

# Generate table
descriptive_tab =
  tableby( ~ unemployment + 
           urbanization +
           median_household_income +
           perc_population_with_high_school_degree +
           perc_non_citizen +
           gini_index +
           perc_non_white +
           hate_crimes_per_100k_splc,
           data = hate_df,
           control = my_controls)

summary(
  descriptive_tab,
  title = "Table 1: Descriptive Statistics: Hate Crimes Data",
  labelTranslations = my_labels,
  text = T)
```
# Remove Missing Data

```{r}
hate_nona_df = # Removing rows with missing values from the dataset
  hate_df %>% 
  drop_na()
```

# Distribution of Outcome Data

Plot a histogram of raw outcome data (hate crimes per 100k) to assess distribution shape.

```{r message = FALSE, warning = FALSE}
hate_df %>% 
  ggplot(aes(x = hate_crimes_per_100k_splc, y = ..density..)) +
  geom_histogram(bins = 11) +
  geom_density(alpha = 0.2, color = "blue") +
  labs(
    x = "Hate Crimes per 100k",
    y = "Density",
    title = "Histogram of Hate Crimes Data"
  )
```

These data look skewed, so we use the Box-Cox method to determine the best transformation for the data. First, fit a linear model with all main effects.

```{r}
full_lm = lm(
  hate_crimes_per_100k_splc
  ~ unemployment + 
    urbanization +
    median_household_income +
    perc_population_with_high_school_degree +
    perc_non_citizen +
    gini_index +
    perc_non_white,
  data = hate_nona_df
)
```

Run boxcox on this model.

```{r}
MASS::boxcox(full_lm)
```

The optimal value of $Y^a$ is near 0, indicating that a natural log transformation of the outcome for all practical intents and purposes is best. We proceed with the log transformation. 


Create a histogram of log-transformed outcome data (hate crimes per 100k).

```{r message = FALSE, warning = FALSE}
hate_df %>% 
  ggplot(aes(x = log(hate_crimes_per_100k_splc), y = ..density..)) +
  geom_histogram(bins = 11) +
  geom_density(alpha = 0.2, color = "blue") +
  labs(
    x = "Hate Crimes per 100k (Log Scale)",
    y = "Density",
    title = "Histogram of Hate Crimes Per 100k on Log Scale"
  )
```

This plot looks less skewed.

# Examining Potential Multicollinearity

Examine correlations between predictors.

```{r}
hate_df %>% 
  select(
    hate_crimes_per_100k_splc,
    median_household_income,
    perc_population_with_high_school_degree,
    perc_non_citizen,
    gini_index,
    perc_non_white
    ) %>%
  cor(use = "complete.obs") %>% # Ignoring NA values
  round(., 2)
```

Based on this output, the following pairs of variables have a correlation of 60% or higher:

* Percentage non-citizens & percentage non-white (0.75)

* Median household income & percentage of population with a high school degree (0.65)

Use a pairs plot to visually assess potential multicollinearity.

```{r}
hate_df %>% 
  select(
    hate_crimes_per_100k_splc,
    median_household_income,
    perc_population_with_high_school_degree,
    perc_non_citizen,
    gini_index,
    perc_non_white
    ) %>% 
  pairs()
```

# Selecting a Model Using the Stepwise Approach

First, consider all main effects in the model, using a log transformation of the outcome.

```{r}
full_log_lm = lm(
  log(hate_crimes_per_100k_splc)
  ~ unemployment + 
    urbanization +
    median_household_income +
    perc_population_with_high_school_degree +
    perc_non_citizen +
    gini_index +
    perc_non_white,
  data = hate_nona_df
)

summary(full_log_lm)
```

Use the Stepwise approach.

```{r, results = FALSE}
step(full_log_lm, direction = "both")
```

This procedure retains the following two predictors:

* Precent population with high school degree

* Gini index


Fit a linear regression model based on the results of the stepwise procedure.
```{r stepwise}
stepwise_log_lm = lm(
  log(hate_crimes_per_100k_splc)
  ~ perc_population_with_high_school_degree +
    gini_index,
  data = hate_nona_df)
```

Check model assumptions using this model.
```{r}
par(mfrow = c(2, 2))
plot(stepwise_log_lm)
```

# Influential Points

Determine if DC is an influential point quantitatively using the Cook’s value.

```{r}
par(mfrow = c(2, 2))
plot(full_log_lm)
```
Check for influential points and create a dataframe without the Washington, DC point to see what impact that has on the model.

Formalize if DC is an influential point quantitatively using the Cook’s value

Using Cook's D and studentized residuals, DC could be an influential point. Cook's D is 0.491, close to the threshold of 0.5. The studentized residual is not greater than 2.5 for any variable. However, DFFIT is greater than 1. Could be cause for concern. Regression analysis shows it is influential, so need to delete.
```{r}
plot(stepwise_log_lm)
influence.measures(stepwise_log_lm)
stu_res<-rstandard(stepwise_log_lm)
outliers_y<-stu_res[abs(stu_res)>2.5]
outliers_y

summary(stepwise_log_lm)
full_nodc = lm(log(hate_crimes_per_100k_splc)~perc_population_with_high_school_degree+gini_index,data=hate_nona_df[-9,])
summary(full_nodc)
```

# Interactions

Check for interactions.

Fit a linear model with all two-way interactions and investigate which interactions are significant.
```{r, results = FALSE}
full_int_lm = lm(log(hate_crimes_per_100k_splc)~(.-state)^2, data = hate_nona_df)
summary(full_int_lm)
```


```{r, results = FALSE}
hate_nona_df %>% 
  ggplot(aes(x = median_household_income, y = log(hate_crimes_per_100k_splc), color = unemployment)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE) +
  labs(x = "Median Household Income",
       y = "log(Hate Crimes Per 100k splc)",
       title = "Interaction Plot for Unemployment and Median Household Income")

hate_nona_df %>% 
  ggplot(aes(x = median_household_income, y = log(hate_crimes_per_100k_splc), color = urbanization)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE) +
  labs(x = "Median Household Income",
       y = "log(Hate Crimes Per 100k splc)",
       title = "Interaction Plot for Urbanization and Median Household Income")
```

There were three significant interactions, two of which occur between a categorical and continuous variable, between median household income and unemployment, and median household income and urbanization. Looking at the interaction plots between these variables we do see that the lines for the two levels of the categorical variables cross, indicating interaction. 

Perform a stratified analysis on these 
```{r}
# Stratified analysis for unemployment

unemployment_low = hate_nona_df %>% 
  filter(unemployment == "low") %>% 
  select(-unemployment)

unemployment_high = hate_nona_df %>% 
  filter(unemployment == "high") %>% 
  select(-unemployment)

unemployment_low_lm = lm(log(hate_crimes_per_100k_splc)~.-state, data = unemployment_low)
summary(unemployment_low_lm)

unemployment_high_lm = lm(log(hate_crimes_per_100k_splc)~.-state, data = unemployment_high)
summary(unemployment_high_lm)
```

Median household income coefficients have different signs when unemployment is low vs high

```{r}

urbanization_low = hate_nona_df %>% 
  filter(urbanization == "low") %>% 
  select(-urbanization)

urbanization_high = hate_nona_df %>% 
  filter(urbanization == "high") %>% 
  select(-urbanization)

# Stratified analysis for urbanization

urbanization_low_lm = lm(log(hate_crimes_per_100k_splc)~.-state, data = urbanization_low)
summary(urbanization_low_lm)

urbanization_high_lm = lm(log(hate_crimes_per_100k_splc)~.-state, data = urbanization_high)
summary(urbanization_high_lm)

## Median household income coefficients have different magnitudes when urbanization is low vs high
```
Stratifying on unemployment we see that the coefficient for median household income is positive when unemployment is low and negative when unemployment is high. When we stratify on urbanization, we see that the coefficient for median household income has a higher magnitude when urbanization is low (although both coefficients are negative). These stratified analyses indicate that interactions do exist.

Include these interaction terms in the full model to check for significance.
```{r}
interaction_log_lm = lm(
  log(hate_crimes_per_100k_splc)
  ~ perc_population_with_high_school_degree
  + gini_index
  + median_household_income 
  + unemployment + urbanization 
  + median_household_income*unemployment 
  + median_household_income*urbanization,
  data = hate_nona_df)

summary(interaction_log_lm)
```

Holding Gini index and percent of population with high school degree constant, both interactions are not significant predictors of hate crime incidents. They are not included in the final model.
